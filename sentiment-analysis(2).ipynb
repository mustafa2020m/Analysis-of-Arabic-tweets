{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;\n",
    "            background-color:#3f4d6f;font-size:150%;\n",
    "            font-family:Nexa;letter-spacing:0.5px\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b> | Importing packages</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import sklearn \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('C:/Users/User/Desktop/data')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;\n",
    "            background-color:#3f4d6f;font-size:150%;\n",
    "            font-family:Nexa;letter-spacing:0.5px\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b> | define functions</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tqdm import tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import stem\n",
    "from sklearn import metrics\n",
    "\n",
    "# Define preprocess function for Arabic text\n",
    "def preprocess_arabic_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^ء-ي\\s]', ' ', text)  # Adjust the range based on your specific needs\n",
    "    # Remove emojis and non-word characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove Twitter handles\n",
    "    text = re.sub(r'@[^\\s]+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'\\B#\\S+', '', text)\n",
    "    # Remove single characters\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', '', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('arabic'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Join the words back into a string\n",
    "    processed_text = ' '.join(words)\n",
    "    return processed_text\n",
    "\n",
    "# Define function to read TSV file\n",
    "def read_tsv(data_file):\n",
    "    text_data = list()\n",
    "    labels = list()\n",
    "    infile = open(data_file, encoding='utf-8')\n",
    "    for line in infile:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        label, text = line.split('\\t')\n",
    "        text_data.append(text)\n",
    "        labels.append(label)\n",
    "    return text_data, labels\n",
    "\n",
    "# Load data from files\n",
    "def load(pos_train_file, neg_train_file, pos_test_file, neg_test_file):\n",
    "    pos_train_data, pos_train_labels = read_tsv(pos_train_file)\n",
    "    neg_train_data, neg_train_labels = read_tsv(neg_train_file)\n",
    "\n",
    "    pos_test_data, pos_test_labels = read_tsv(pos_test_file)\n",
    "    neg_test_data, neg_test_labels = read_tsv(neg_test_file)\n",
    "\n",
    "    x_train = pos_train_data + neg_train_data\n",
    "    y_train = pos_train_labels + neg_train_labels\n",
    "\n",
    "    x_test = pos_test_data + neg_test_data\n",
    "    y_test = pos_test_labels + neg_test_labels\n",
    "\n",
    "    print('train data size:{}\\ttest data size:{}'.format(len(y_train), len(y_test)))\n",
    "    print('train data: # of pos:{}\\t# of neg:{}\\t'.format(y_train.count('pos'), y_train.count('neg')))\n",
    "    print('test data: # of pos:{}\\t# of neg:{}\\t'.format(y_test.count('pos'), y_test.count('neg')))\n",
    "    print('------------------------------------')\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Function to perform sentiment analysis\n",
    "def do_sa(n, my_classifier, name, my_data):\n",
    "    x_train, y_train, x_test, y_test = my_data\n",
    "    print('parameters')\n",
    "    print('n grams:', n)\n",
    "    print('classifier:', my_classifier.__class__.__name__)\n",
    "    print('------------------------------------')\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', TfidfVectorizer(min_df=0.0001, max_df=0.5,\n",
    "                                 analyzer='word', lowercase=False,\n",
    "                                 ngram_range=(1, n))),\n",
    "        ('clf', my_classifier),\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(x_train, y_train)\n",
    "    feature_names = pipeline.named_steps['vect'].get_feature_names_out()\n",
    "\n",
    "    y_predicted = pipeline.predict(x_test)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(classification_report(y_test, y_predicted, target_names=['pos', 'neg']))\n",
    "\n",
    "    # Print the confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "    print(cm)\n",
    "    print('# of features:', len(feature_names))\n",
    "    print('sample of features:', random.sample(list(feature_names), 40))\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    return name, n, accuracy, precision, recall\n",
    "\n",
    "# Main function to orchestrate the entire process\n",
    "def main(pos_train_file, neg_train_file, pos_test_file, neg_test_file):\n",
    "    # Load data\n",
    "    x_train, y_train, x_test, y_test = load(pos_train_file, neg_train_file, pos_test_file, neg_test_file)\n",
    "\n",
    "    # Preprocess text data\n",
    "    x_train_processed = [preprocess_arabic_text(text) for text in x_train]\n",
    "    x_test_processed = [preprocess_arabic_text(text) for text in x_test]\n",
    "\n",
    "    # Train and evaluate classifier\n",
    "    my_classifier = MultinomialNB()\n",
    "    n = 2  # Example n-gram value\n",
    "    classifier_name = 'Multinomial Naive Bayes'\n",
    "    data = (x_train_processed, y_train, x_test_processed, y_test)\n",
    "    results = do_sa(n, my_classifier, classifier_name, data)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;\n",
    "            background-color:#3f4d6f;font-size:150%;\n",
    "            font-family:Nexa;letter-spacing:0.5px\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b> |Setup experiments</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size:47000\ttest data size:11751\n",
      "train data: # of pos:23879\t# of neg:23121\t\n",
      "test data: # of pos:5970\t# of neg:5781\t\n",
      "------------------------------------\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: LinearSVC\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.76      0.78      0.77      5781\n",
      "         neg       0.78      0.76      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4524 1257]\n",
      " [1451 4519]]\n",
      "# of features: 13795\n",
      "sample of features: ['آرمييز', 'ملآيين', 'مجال', 'دربا', 'ٱن', 'الدولة', 'ذم', 'احط', 'أرواح', 'دووم', 'بعدد', 'ارض', 'نرد', 'بال', 'شاف', 'بلادنا', 'المسلسل', 'صرح_الترف_للتبادل', 'خشع', 'للحبيب', 'وأجعلها', 'أصبر', 'تصوير', 'كبد', 'تصعب', 'اياها', 'تكاليف', 'فانصرهم', 'أطفال', 'ألا', 'at', 'طوينا', 'ودا', 'ﻳﺤﺒﻚ', 'لو', 'فيشرب', 'الأعمال', 'للغد', 'تسليم', 'نشوفك']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: SVC\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.84      0.81      5781\n",
      "         neg       0.83      0.76      0.79      5970\n",
      "\n",
      "    accuracy                           0.80     11751\n",
      "   macro avg       0.80      0.80      0.80     11751\n",
      "weighted avg       0.80      0.80      0.80     11751\n",
      "\n",
      "[[4864  917]\n",
      " [1433 4537]]\n",
      "# of features: 13795\n",
      "sample of features: ['اخلص', 'عنصرية', 'جبريل', 'عرش', 'سلامته', 'نفسي', 'بالكثير', 'الحفله', 'عما', 'الأخير', 'قدامي', 'لاتتأخروا', 'ضحكت', 'ياه', 'تخريج', 'توكل', 'ابهى', 'رقموا', 'الجيش_السلماني', 'علامات', 'اللسان', 'السيادي', 'شديد', '18', 'للفيحاء', 'يتقدم', 'المحبه', 'بحمد', 'دعم', 'فانصرهم', 'بعمر', 'برحيل', 'تلوي', 'يحترمڪ', 'خلصنا', 'الديوث', 'هايدي', 'يغادر', 'السياره', 'الحمد']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: MultinomialNB\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.75      0.78      0.76      5781\n",
      "         neg       0.78      0.75      0.76      5970\n",
      "\n",
      "    accuracy                           0.76     11751\n",
      "   macro avg       0.76      0.76      0.76     11751\n",
      "weighted avg       0.76      0.76      0.76     11751\n",
      "\n",
      "[[4489 1292]\n",
      " [1513 4457]]\n",
      "# of features: 13795\n",
      "sample of features: ['نسمع', 'سألوا', 'أبكيك', 'مطريتين', 'صبياء', 'يرى', 'الأماكن', 'بأنه', 'بهجرك', 'تجري', 'رأى', 'يشجعه', 'لنادي', 'موسى', 'عقلاء', 'ودموعي', 'يفعلها', 'ياولد', 'لفريق', 'قربت', 'ثقيلتان', 'أسكن', 'التعبير', 'الهلالية', 'حتكون', 'الأفكار', 'الكل_رابح_مع_اسرع', 'القلوب', 'واللهي', 'واذا', 'الفرحه', 'نومتي', 'ووجدنا', 'نيج', 'اليسار', 'تزوج', 'توهم', 'تسلك', 'تحطين', 'أسقنا']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: BernoulliNB\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.72      0.82      0.77      5781\n",
      "         neg       0.80      0.69      0.74      5970\n",
      "\n",
      "    accuracy                           0.76     11751\n",
      "   macro avg       0.76      0.76      0.76     11751\n",
      "weighted avg       0.76      0.76      0.76     11751\n",
      "\n",
      "[[4758 1023]\n",
      " [1821 4149]]\n",
      "# of features: 13795\n",
      "sample of features: ['صاحبة', 'النوايا', 'الأفريقية', 'لطف', 'الراس', 'غيرت', 'ينتظر', 'رسوم', 'الإمارات', 'فأغفر', 'الجائزة', 'المتواجدين', 'اوضاعي', 'ليك', 'ياترى', 'زالت', 'يحول', 'البنات', 'فش', 'أوجاعك', 'رجاله', 'احسب', 'ويستجيب', 'عشانك', 'التلفزيون', 'الإسلامية', 'نتبلل', 'فيارب', 'اتحادي', 'والتوفيق', 'يرون', 'علمني', 'حكينا', 'امبارح', 'بربك', 'جرحت', 'دربك', 'ساعات', 'حرامك', 'ماكا']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: SGDClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.73      0.82      0.77      5781\n",
      "         neg       0.80      0.71      0.75      5970\n",
      "\n",
      "    accuracy                           0.76     11751\n",
      "   macro avg       0.77      0.76      0.76     11751\n",
      "weighted avg       0.77      0.76      0.76     11751\n",
      "\n",
      "[[4734 1047]\n",
      " [1731 4239]]\n",
      "# of features: 13795\n",
      "sample of features: ['الافضل', 'سويسرا', 'ترخولي', 'والاهلي', 'وردا', 'تقعد', 'الثناء', 'اعماقكم', 'برمضان', 'تنفسوا', 'واستمد', 'وقلوا', 'ﺣﺘﻰ', 'وأ', 'وداعت', 'نعجان', 'طلبتك', 'العذبة', 'والح', 'يبقا', '_آرجي', 'اخرتها', 'يفعل', 'جعلني', 'طارق', 'ليالي', 'سقط', 'رضاء', 'ارتكبنا', 'للتغريدة', 'شيخ', 'ثقافة', 'لازلت', 'معاه', 'هزت', 'ابتسمت', 'المتقين', 'المره', 'تعجز', 'زحمة']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: LogisticRegression\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.75      0.79      0.77      5781\n",
      "         neg       0.78      0.75      0.76      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4556 1225]\n",
      " [1519 4451]]\n",
      "# of features: 13795\n",
      "sample of features: ['قانون', 'اتوجهو', 'الحي', 'تخيلوا', 'وم', 'دواء', 'عمارا', 'الحرمين', 'يجونا', 'مبيعات', 'منحلي', 'نتمنى', 'جناته', 'أحيا', 'مأجور_ياانا', 'بنام', 'حكاية', 'الأمطار', 'خيط', 'دقايق', 'البشر', 'تكونوا', 'امطار_الخرج', 'اخيرا', 'فخورا', 'ﺩﻣﻌﻚ', 'حرفيا', 'الدني', 'إنني', 'الشفايف', 'لأجلك', 'فلازم', 'وعافية', 'للكل', 'بزعل', 'البرسل', 'اهناك', 'ولمعة', 'طيار', 'شفقة']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: MLPClassifier\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.78      0.77      5781\n",
      "         neg       0.78      0.77      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4482 1299]\n",
      " [1375 4595]]\n",
      "# of features: 13795\n",
      "sample of features: ['اييه', 'ورجعت', 'بتمنى', 'وأجمل', 'معلش', 'مفيد', 'الويكند', 'ولكم', 'النفسيات', 'وطبعا', 'لأي', 'كذاا', 'ترا', 'ايام', 'خيخه', 'اشد', 'وبأذن', 'الصداع', 'تسمح', 'التجمع', 'عضلة', 'يصف', 'احط', 'ترفع', 'الوضع', 'حلمي', 'أفضل', 'آرمييز', 'عليهما', 'احمد', 'الدرس', 'الشافعي', 'مستواك', 'الكل_رابح_مع_اسرع', 'تف', 'وارهابيين', 'الاسم', 'قرعة', 'وتشويه', 'جاهز']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: DecisionTreeClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.54      0.96      0.69      5781\n",
      "         neg       0.85      0.19      0.32      5970\n",
      "\n",
      "    accuracy                           0.57     11751\n",
      "   macro avg       0.69      0.58      0.50     11751\n",
      "weighted avg       0.69      0.57      0.50     11751\n",
      "\n",
      "[[5570  211]\n",
      " [4814 1156]]\n",
      "# of features: 13795\n",
      "sample of features: ['فهمت', 'مج', 'فقطعت', 'كت', 'عمر', 'اجعل', 'قادمة', 'ساكن', 'نحط', 'مابداخلك', 'اتقدم', 'رب', 'المتاريس', 'لأكثر', 'أحياء', 'بمنع', 'غزير', 'محبا', 'خايفة', 'شغله', 'بالبراقع', 'صنعاء', 'بيد', 'بدايتها', 'سيس', 'الآتي', 'لأهل', 'يصدق', 'تخف', 'ياحظي', 'لفتره', 'ستكون', 'طايش', 'انتى', 'ساعتين', 'ماجيستك', 'رن', 'صدر', 'وضيع', 'صباح_ال']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: RandomForestClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.85      0.80      5781\n",
      "         neg       0.83      0.75      0.79      5970\n",
      "\n",
      "    accuracy                           0.80     11751\n",
      "   macro avg       0.80      0.80      0.80     11751\n",
      "weighted avg       0.80      0.80      0.80     11751\n",
      "\n",
      "[[4892  889]\n",
      " [1486 4484]]\n",
      "# of features: 13795\n",
      "sample of features: ['الصالحين', 'قرارات', 'معها', 'FIFA', 'تتخاذل', 'لحنها', 'كانه', 'كالتالي', 'تكفى', 'قسما', 'وراه', 'لحظﺎﺕ', 'غالبا', 'الخيرات', 'الدفعه', 'بدايتها', 'تقصد', 'بس', 'تعامل', 'وبطلت', 'يشبه', 'طفل', 'تحك', 'الدراما', 'تبني', 'لطف', 'قاعد', 'قرد', 'مالنا', 'ماينفع', 'فكرة', 'البحري', 'تهدي', 'زوجتي', 'هالذيابه', 'هوب', 'يحس', 'مؤلمة', 'ھادئ', 'اكيد']\n",
      "parameters\n",
      "n grams: 1\n",
      "classifier: KNeighborsClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.86      0.46      0.60      5781\n",
      "         neg       0.64      0.93      0.76      5970\n",
      "\n",
      "    accuracy                           0.70     11751\n",
      "   macro avg       0.75      0.69      0.68     11751\n",
      "weighted avg       0.75      0.70      0.68     11751\n",
      "\n",
      "[[2673 3108]\n",
      " [ 435 5535]]\n",
      "# of features: 13795\n",
      "sample of features: ['مثلها', 'أسعدنا', 'عبدالمحسن', 'اعد', 'غيوم', 'لرؤيتنا', 'الخفي', 'البكيريه', 'تخصصك', 'وممكن', 'للتماسيح', 'درجة', 'هالتغريدة', 'رتويت', 'عذابه', '16', 'حبيتك', 'نتايج', 'واقع', 'فرنسا', 'تبرع', 'يعلق', 'ياقلبي', 'جواد', 'كلي', 'للحين', 'خاطرك', 'أحبة', 'وتخبز', 'جايب', 'الفؤاد', 'للإنتاج', 'الصين', 'عزله', 'الكلمه', 'لدعم', 'يجهزون', 'لايدخل', 'ظل', 'ديسباتش']\n",
      "train data size:47000\ttest data size:11751\n",
      "train data: # of pos:23879\t# of neg:23121\t\n",
      "test data: # of pos:5970\t# of neg:5781\t\n",
      "------------------------------------\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: LinearSVC\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.76      0.78      0.77      5781\n",
      "         neg       0.78      0.77      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4520 1261]\n",
      " [1398 4572]]\n",
      "# of features: 27834\n",
      "sample of features: ['سیستجیب', 'تعب', 'بعظمته', 'قريتها', 'كل الحب', 'الفرصه', 'وحاجات تقضى', 'اللهم اجعل', 'أي منطقة', 'ولن تخيب', 'محلل', 'ببهه', 'اضغاث احلام', 'الرس عنيزة', 'احمد الحربي', 'بشخص', 'تضيع', 'الخازوق', 'انتظرك', 'للمره', 'عبارات', 'أشوف بك', 'من الغياب', 'أي شئ', 'المواقف', 'ﻓﻴﻚ', 'خروج', 'مثل', 'العسل كلوو', 'وقاصدك', 'فعالية', 'ذكره', 'قال لا', 'قوة الهلال', 'لنضحك للغد', 'حكم', 'همثون77', 'فعلا والله', 'يغني', 'يحبون']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: SVC\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.84      0.80      5781\n",
      "         neg       0.83      0.76      0.79      5970\n",
      "\n",
      "    accuracy                           0.80     11751\n",
      "   macro avg       0.80      0.80      0.80     11751\n",
      "weighted avg       0.80      0.80      0.80     11751\n",
      "\n",
      "[[4851  930]\n",
      " [1422 4548]]\n",
      "# of features: 27834\n",
      "sample of features: ['لوصلك', 'مجموعه', 'شكلنا', 'تفوزون', 'متى تتحقق', 'وإن ضعفت', 'وأهم', 'مذنبا أنت', 'الصالحين', 'الموجود في', 'يله', 'مواد', 'لايجوز بعض', 'بعضه', 'مفاجئ غير', 'رب اجعل', 'صلى', 'رباه', 'يبدع في', 'مابقى', 'ضرب رصاص', 'تميل قلوبنا', 'الدعم_السعودي', 'الجهاد', 'أحزن', 'أسطورية', 'هم أنيقين', 'هل هي', 'الجنة لا', 'نطاج', 'اخي ماذا', 'نفرح', 'بدعاء', 'شيء في', 'أعطاه', 'القراءة', 'ياغرفة طوا', 'توني', 'زيهم', 'اصلك']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: MultinomialNB\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.75      0.79      0.77      5781\n",
      "         neg       0.79      0.75      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4580 1201]\n",
      " [1512 4458]]\n",
      "# of features: 27834\n",
      "sample of features: ['ولآحول ولا', 'ومافيه', 'هوليجنز', 'إبطاء', 'حطيت', 'تسابقني', 'ﺍﻟﻮﺿﻮﺀ', 'اوف', 'الحلوين', 'الله يبشرني', 'عشي تافه', 'بنات', 'النصر من', 'في حياتي', 'أظن', 'عنواني', 'الطقس واخبار', 'فإنك', 'أصعب', 'انني', 'كاس العناء', 'لفريق', 'تحبك كثيرا', 'الأب', 'وفعلوا', 'فرصة', 'سيستجيب', 'لا تصدر', 'سنه يشمل', 'كسالى', 'يا عيال', 'حاجه اسمها', 'يظنون', 'فايده', 'التغاريد', 'والشكر', 'اصير', 'بسلك', 'ان شاء', 'اثبات الذات']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: BernoulliNB\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.72      0.86      0.78      5781\n",
      "         neg       0.83      0.67      0.74      5970\n",
      "\n",
      "    accuracy                           0.76     11751\n",
      "   macro avg       0.77      0.76      0.76     11751\n",
      "weighted avg       0.77      0.76      0.76     11751\n",
      "\n",
      "[[4944  837]\n",
      " [1965 4005]]\n",
      "# of features: 27834\n",
      "sample of features: ['تغذية رشاقة', 'وافضل', 'آخر الأحباب', 'أروع', 'هريرة رضي', 'بأسمى', 'ماقلت', 'عرف', 'شخص أنت', 'تعالى لا', 'الرياض', 'أحضر', 'الدولارات وآخر', 'ميت واستجابة', 'خيال', 'اتعاطف', 'لل', 'وتابع السحب', 'حالة تم', 'من شعبان', 'احد بنفوز', 'بس لو', 'إذا بحت', 'الربيع العربي', 'امطار_الرياض', 'ثاني ابتدائي', 'ولا الاتحاد', 'في ظلمة', 'آلحيآة', 'بس انا', 'كرهي', 'هديل_شقير_الشقير', 'الباب وتدعو', 'نواف_محمد_فرحان_الايداء', 'شكر أختي', 'ونقدر', 'وبيقفوا', 'الاستجابه', 'نسمع ونبصر', 'انتهى']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: SGDClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.74      0.83      0.78      5781\n",
      "         neg       0.81      0.72      0.76      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.78      0.77      0.77     11751\n",
      "weighted avg       0.78      0.77      0.77     11751\n",
      "\n",
      "[[4779 1002]\n",
      " [1671 4299]]\n",
      "# of features: 27834\n",
      "sample of features: ['اللهم هب', 'والتحفيز', 'التاسعة والعشرون', 'أبتسامتي', 'في الرق', 'مسيار في', 'أجنبي', 'امل', 'بذكراك', 'عاشت', 'النرويج مع', 'يخيب لنا', 'من روحي', 'منذ أمس', 'في قمة', 'الحضور الجاف', 'احنا', 'قناص', 'بالرحمة وان', 'مالقيت', 'اني', 'أقدم', 'يحلم فيني', 'مكبرات الصوت', 'انحب', 'ما يقولهم', 'الثقة', 'الشقاء وسوء', 'سنه لح', 'حكوميه الدعوه', 'متابعة حساب', 'بعاقل من', 'لتتأدب الزوج', 'موجع', 'الرجاء الالتزام', 'على أمل', 'بلوغ', 'معلش', 'ولا', 'تحت التغريدة']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: LogisticRegression\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.76      0.80      0.78      5781\n",
      "         neg       0.79      0.76      0.77      5970\n",
      "\n",
      "    accuracy                           0.78     11751\n",
      "   macro avg       0.78      0.78      0.78     11751\n",
      "weighted avg       0.78      0.78      0.78     11751\n",
      "\n",
      "[[4601 1180]\n",
      " [1461 4509]]\n",
      "# of features: 27834\n",
      "sample of features: ['الأزهر والشفيع', 'يا اخي', 'كجمال', 'من الأيام', 'من خلف', 'أنت الكريم', 'يوزع', 'في قضاء', 'مستعدين', 'وقاصدك', 'والكرامة والعدالة', 'ليتني', 'بوسط', 'ما هو', 'أفكارك أكثر', 'غيرته', 'مخزن', 'عليكم يسر', 'والكلام الزايد', 'ضربني وبكى', 'آنسان تحبه', 'ذو', 'ياجعلها في', 'بجمال', 'تتألم', 'عآادل', 'محب', 'اعتصا', 'وفرحة', 'سآاعة', 'خلاص قيم', 'الأحمر على', 'هي حركة', 'الطيور تهاجر', 'بخصوص عينه', 'ينتظرنا كل', 'التذكير بهذا', 'يعلم ما', 'من هنا', 'نشعر']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: MLPClassifier\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.77      0.77      5781\n",
      "         neg       0.78      0.77      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4480 1301]\n",
      " [1370 4600]]\n",
      "# of features: 27834\n",
      "sample of features: ['التخرج', 'لنعمة', 'الموجود في', 'تورينا', 'كبير مش', 'كأن', 'داير', 'عوضني خيرا', 'كلماته', 'منا يا', 'وان اليه', 'ضعيفه واضعف', 'ابتعدنا', 'المحترفي', 'ورود', 'اوقات', 'سعودية', 'المدينه', 'ﺿﺮ ﺗﻜﺸﻔﻪ', 'تخونه', 'معقولة', 'فأوجعهم ما', 'مرتاح الحين', 'عطوره', 'وسخونة وهي', 'كيلو', 'مدينه', 'ممتعة', 'تنبييه الساعه', 'وسعيد', 'بطن', 'عيد ميلادي', 'هذا المساء', 'فوقهم', 'صحيحة', 'على الشيطان', 'بسهولة ثقتنا', 'تصلي', 'وصول', 'من شهر']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: DecisionTreeClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.54      0.96      0.69      5781\n",
      "         neg       0.85      0.19      0.31      5970\n",
      "\n",
      "    accuracy                           0.57     11751\n",
      "   macro avg       0.69      0.58      0.50     11751\n",
      "weighted avg       0.69      0.57      0.50     11751\n",
      "\n",
      "[[5571  210]\n",
      " [4819 1151]]\n",
      "# of features: 27834\n",
      "sample of features: ['من مستغفر', 'سيئون', 'انتظار الفرح', 'لاوالله', 'غرقانه', 'ممنوعة', 'لكم التعليق', 'الدعاء كأنما', 'عيناك', 'الجديدة', 'أسافر مع', 'فض اعتصام', 'أول بيضة', 'الصادقة أفضل', 'أصدق', 'بعد ساعة', 'ولا يذهب', 'كاد', 'وتضحك', 'أصبحت سلوكيات', 'ثقافة', 'ياقلبي', 'عمرى بأقول', 'ضجيج', 'تكون', 'الفضول', 'الأماني مهما', 'ماله', 'الحياة متسع', 'أرجوك', 'ما بغوا', 'ويهديهم', 'كذا اليوم', 'ميت اللهم', 'وأرضى', 'مهما كانت', 'لو كنت', 'الوصول الى', 'الاتحاد في', 'ما خاب']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: RandomForestClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.84      0.80      5781\n",
      "         neg       0.83      0.75      0.79      5970\n",
      "\n",
      "    accuracy                           0.80     11751\n",
      "   macro avg       0.80      0.80      0.79     11751\n",
      "weighted avg       0.80      0.80      0.79     11751\n",
      "\n",
      "[[4855  926]\n",
      " [1481 4489]]\n",
      "# of features: 27834\n",
      "sample of features: ['حقكم', 'يقول ابن', 'حديثا', 'هل تبحث', 'وانا بصف', 'وادع ربك', 'حر السخونة', 'ستسعد', 'للشابة هديل_شقير_الشقير', 'والنور', 'يدعو', 'لما تحاول', 'موتانا اغسل', 'جيمي', 'اخوه توفى', 'من البيت', 'نقطة التحول', 'رحال', 'كم يطلع', 'كانها', 'الرائد', 'كفي لعند', 'الي قاعد', 'تمثل شعور', 'الجن', 'صحتي', 'تهتم', 'ديسباتش', 'وحيده', 'دم الشهيد', 'الناس لا', 'اللهم أغثنا', 'وآجله', 'الأستاذ', 'بحبها', 'بيدي', 'الأمنيات', 'السهر', 'لعيون', 'زمان ما']\n",
      "parameters\n",
      "n grams: 2\n",
      "classifier: KNeighborsClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.86      0.46      0.60      5781\n",
      "         neg       0.64      0.93      0.76      5970\n",
      "\n",
      "    accuracy                           0.70     11751\n",
      "   macro avg       0.75      0.69      0.68     11751\n",
      "weighted avg       0.75      0.70      0.68     11751\n",
      "\n",
      "[[2656 3125]\n",
      " [ 419 5551]]\n",
      "# of features: 27834\n",
      "sample of features: ['كريهة شو', 'الإجابة نعم', 'أن تعرف', 'من هم', 'للحياه', 'الضعف الجنسي', 'الرسول ندموا', 'تلاوةصباحية', 'راحة بال', 'لاتنسى', 'بخاف', 'الفتوى_والتشريع من', 'لقلبي', 'الاعتصام من', 'لعند رفيقو', 'دعمها', 'الخلود بنشوة', 'الله يعطيه', 'دعوات', 'اتعاطف', 'الكلام المعسول', 'يرحمكم', 'شفتها', 'الله لنا', 'المحترفين والله', 'نسائي', 'المگاريد', 'أول ساعة', 'بالحكي', 'بأنثى واحدة', 'ومبروك للأمة', 'لا تنتظري', 'بدك', 'اجبروا', 'ملاحظة الحل', 'اشكال', 'هالمواقف تصير', 'يستطيع الفوز', 'التشيكي مرشح', 'تحب المطر']\n",
      "train data size:47000\ttest data size:11751\n",
      "train data: # of pos:23879\t# of neg:23121\t\n",
      "test data: # of pos:5970\t# of neg:5781\t\n",
      "------------------------------------\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: LinearSVC\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.76      0.78      0.77      5781\n",
      "         neg       0.78      0.76      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4513 1268]\n",
      " [1409 4561]]\n",
      "# of features: 39232\n",
      "sample of features: ['أول خيانه', 'حبيبها', 'بنسلين على', 'معروف', 'النومه', 'اجي', 'غير ذي زرع', 'في الأرض', 'اللي منك تقلبي', 'وتوفيقه أنجزنا حفر', 'هكذا', 'العظيم أن يجعلكم', 'جدها وتتحدث عن', 'دياثه', 'وسرقوه بل اقول', 'لاكن مؤثر', 'شي ما', 'حلاوه', 'صح لسانك', 'امنجية لي مخربين', 'آلوفي محد ينگره', 'البرسل', 'ادارتنا ربي يحفظكم', 'لا ترحل', 'وحتى', 'يغني له هالبيتين', 'يحسن من', 'مخلوق', 'زي ما', 'لو هي', 'وينقذ', 'الابن', 'نفسآ', 'النصر_الاتحاد تبقى', 'الكورة أفريقاا', 'مسدسين مافي', 'يحرك شعره منهم', 'التشكيل كنا', 'الصعب', 'الأحد']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: SVC\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.84      0.80      5781\n",
      "         neg       0.83      0.76      0.79      5970\n",
      "\n",
      "    accuracy                           0.80     11751\n",
      "   macro avg       0.80      0.80      0.80     11751\n",
      "weighted avg       0.80      0.80      0.80     11751\n",
      "\n",
      "[[4846  935]\n",
      " [1422 4548]]\n",
      "# of features: 39232\n",
      "sample of features: ['نموذج من', 'عليك يانور', 'قتےل ٱنسےٱن', 'إشراقة الصباح الأناقة', 'ويعوضها', 'الذين آمنوا', 'قرار', 'طيب وش', 'معلومة جدا خطيرة', 'وصار الفريق بدون', 'يارب إني', 'لاحد', 'خيير', 'لا يمل ولا', 'الفين', 'التعاون', 'وترديد نشيد نادي', 'إمتنان على', 'مع دكتورة رندة', 'يستميت', 'شيخة عرب', 'وﻵ', 'الوطني', 'صور wallpaper لموبايلك', 'كل الطيور', 'الاحتلال طفل تم', 'ما تبكي', 'الطيبه', 'الكيان', 'أم وأب', 'واللحق على الباب', 'الذي قدمه', 'خقيت آنا', 'اللهم بك', 'قبر', 'سبب خوف المهم', 'العربى احنا الشعب', 'وادب واللي', 'وهجد غوميز صاحوا', 'الفوز']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: MultinomialNB\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.75      0.79      0.77      5781\n",
      "         neg       0.79      0.75      0.77      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4592 1189]\n",
      " [1504 4466]]\n",
      "# of features: 39232\n",
      "sample of features: ['19 تابع آرمييز', 'كلاس بالاسم ضمان', 'صلي وسلم على', 'والطيب تكتب', 'صبح', 'حافظ', 'يطلعونك', 'وتعد على', 'والبركة ادعموا اختكم', 'وجروه', 'قلبگ', 'باك', 'من البعد', 'ما تكافئونه', 'قال ابن', 'شي هذا حقك', 'أصعب شي لما', 'عاد يغريني رجوعك', 'يامن تملک', 'بعض البشر', 'عربي قرشي', 'ما توصلت', 'جسمك', 'وظيفته', 'تفاصيل', 'وخد الباك', 'في وسط', 'فقرها', 'نحونا', 'مباراة انتحارية لا', 'الفار في عهد', 'وفا', 'بعاقل', 'تغريداتك لملايين المتابعين', 'الاستفادة', 'مضيء', 'خلايا', 'توقعي', 'تبرع كلى', 'أن تصنع لي']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: BernoulliNB\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.71      0.87      0.78      5781\n",
      "         neg       0.84      0.65      0.74      5970\n",
      "\n",
      "    accuracy                           0.76     11751\n",
      "   macro avg       0.77      0.76      0.76     11751\n",
      "weighted avg       0.78      0.76      0.76     11751\n",
      "\n",
      "[[5029  752]\n",
      " [2061 3909]]\n",
      "# of features: 39232\n",
      "sample of features: ['على كيفهم يبونك', 'باسمي', 'مسويه', 'أهل قطر', 'غالي الرياض مطر', 'هناجر مستودعات ترميمات', 'ودون', 'أعرف', 'لعيب يا محمد', 'لأمراض كثيرة', 'دهان اوسكار جذاب', 'عبراتها بقلمي جديد', 'غادرتني دون', 'وبيشيلو في', 'انتهت تاني', 'يكل', 'يزعل', 'الصغيرة', 'فقط سقطت معها', 'من وقتك وقل', 'في خير وتاريخه', 'أبوعمر بأقذع', 'هادئا علي الصامتين', 'في ذمتك ماوحشتك', 'وان شاء الله', 'ميرسي', 'ما رددوا', 'إيه قالي', 'إنشغال من أحب', 'حق دون حياء', 'ركن بقلبك', 'لحالات مماثلة من', 'العيش', 'وخير مافيه ونعوذ', 'والله حسيب الحنين', 'الهبوط بشكل', 'الأمل هنا الأمان', 'حبيت هالبنت اول', 'مآ من', 'قطرات']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: SGDClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.74      0.83      0.78      5781\n",
      "         neg       0.81      0.72      0.76      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.78      0.77      0.77     11751\n",
      "weighted avg       0.78      0.77      0.77     11751\n",
      "\n",
      "[[4772 1009]\n",
      " [1651 4319]]\n",
      "# of features: 39232\n",
      "sample of features: ['الزرقاء ام جود', 'افريقيا_يا_صن_داونز صن_داونز', 'بيعرف', 'مع الراحل عمر', 'وبحمده سبحان الله', 'وعيونه الليله تجاوبني', 'اوراق الاحتجاج مركز_التحكيم_الرياضي', 'حفلة من أكبر', 'منصب', 'دائما اللهم', 'ﻛﻞ ﺭﺯﻕ ﺗﺒﺴﻄﻪ', 'زواياه', 'تحمد الله', 'إذا أردتي هجراني', 'الفيفا وفي', 'كم حساب يحتفلون', 'تافه', 'الكوتشيلا', 'يوم أمطرت دارك', 'تلوي', 'يكون تافه كدا', 'صاحب الهاشتاق بليد', 'كل مفاصل عدن', 'كل حال', 'انمي تجنن الأغنية', 'المطر يا', 'نتكاسل أنا', 'الزحام كن روحآ', 'الاتنين وأنتم من', 'الرؤيا', 'سرعة الأخوة', 'كل التباريك', 'كانوا يقصدون الرياض', 'بئر لعام ابتداء', 'شهور تستاهل الزرقاء', 'إلا رسائلك', 'وطنية أو', 'Melon', 'شاطر واللي نايم', 'بسبب الأحوال الجوية']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: LogisticRegression\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.76      0.80      0.78      5781\n",
      "         neg       0.79      0.76      0.77      5970\n",
      "\n",
      "    accuracy                           0.78     11751\n",
      "   macro avg       0.78      0.78      0.78     11751\n",
      "weighted avg       0.78      0.78      0.78     11751\n",
      "\n",
      "[[4604 1177]\n",
      " [1451 4519]]\n",
      "# of features: 39232\n",
      "sample of features: ['الأمل والثقة', 'يوم أمطرت', 'نشاط', 'دورية خلال', 'الثاني قادم', 'حرية', 'مرضى المسلمين ويرحم', 'آمين صباح', 'بالحياه', 'ربنا يهونها علينا', 'يجيني', 'يخرب بيت', 'اليقين من الرياء', 'إليك عس', 'سمعك وانعش', 'اسقاط', 'خيرك', 'صباح التفاؤل', 'ايي', 'من جهه', 'اغضب منه', 'نقص', 'مراسلي', 'يا شافي', 'الدهر', 'ليس له', 'الكيزان', 'بانه', 'حيبدأ اسقاط النظام', 'وخلقك', 'ﺗﻨﺸﺮﻩ ﻭﻓﻲ ﻛﻞ', 'جدا من الأرصاد', 'الي قلبه ضعيف', 'هايدي', 'تحت السرج متداري', 'عند الذهب', 'مساء الخير', 'امرأة', 'نشوف', 'محمد الحزم']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: MLPClassifier\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.77      0.77      5781\n",
      "         neg       0.78      0.77      0.78      5970\n",
      "\n",
      "    accuracy                           0.77     11751\n",
      "   macro avg       0.77      0.77      0.77     11751\n",
      "weighted avg       0.77      0.77      0.77     11751\n",
      "\n",
      "[[4477 1304]\n",
      " [1368 4602]]\n",
      "# of features: 39232\n",
      "sample of features: ['القياسي', 'عن حالتي عقب', 'احسن الناس علي', 'وبتروح في', 'الفوز في', 'سأكمل ساعة بلا', 'أول أغلا', 'نفسي لتشكيلة', 'والمالتي', 'أما العبودية فستبقى', 'الفترة الأولى من', 'ورتويت', 'رئيسين في يومين', 'بدل ما اجلس', 'أحد وفوق الجميع', 'العسل كلوو', 'تموت الأخيرة يبدو', 'الدوري السعودي', 'عندهم استعداد بأنهم', 'طول عمرك تذكرين', 'الكرام أنا فارقه', 'مبرووك', 'ورجعت', 'الخوازيق وكان', 'وجهها وغيرت', 'ما لم يحدث', 'إلى أن', 'لايضيق لنا', 'يصعب', 'تكفوون', 'فقط', 'كف', 'لطف الله', 'ضد أحد', 'حالكم كأنه', 'أحد بالله', 'الصمت إما', 'مبرووك لعشاق', 'من السعادة', 'يايمن']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: DecisionTreeClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.54      0.96      0.69      5781\n",
      "         neg       0.85      0.19      0.31      5970\n",
      "\n",
      "    accuracy                           0.57     11751\n",
      "   macro avg       0.69      0.58      0.50     11751\n",
      "weighted avg       0.69      0.57      0.50     11751\n",
      "\n",
      "[[5571  210]\n",
      " [4818 1152]]\n",
      "# of features: 39232\n",
      "sample of features: ['مطلب واحد عليكم', 'لنكون لمن', 'وليست', 'من سار', 'أنت بحياتي', 'امر', 'المعيوف ينعش آمال', 'مهاجم بالدوري وحمدلله', 'قاتلوا', 'سلم', 'تتوقعون العميد يسويها', 'استطيع', 'شكرا جماهير الهلال', 'شريك', 'مكشر جرب', 'مطمئنا لكل من', 'مسبوقه كلمة يآرب', 'جلال والاربعين جربوع', 'رمضان على', 'دياثه', 'ضايق ولا أدري', 'في نظر عيني', 'الله وأفضل الأيام', 'حيوية نشاط', 'للبعيدة جدا للتي', 'والهداية', 'يتكلمون', 'ماعنده وقت طفى', 'التنازلي', 'بس كل', 'وقتي بذكرآاك', 'درك', 'قائلة لطالما اعتبرناك', 'راحت', 'مساء يوم أمس', 'فائدة الاهلي', 'ونشوفها المربية', 'مارادونا', 'لحظات وأقوى', 'قلوب زرقاء']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: RandomForestClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.77      0.85      0.81      5781\n",
      "         neg       0.84      0.75      0.79      5970\n",
      "\n",
      "    accuracy                           0.80     11751\n",
      "   macro avg       0.80      0.80      0.80     11751\n",
      "weighted avg       0.80      0.80      0.80     11751\n",
      "\n",
      "[[4905  876]\n",
      " [1498 4472]]\n",
      "# of features: 39232\n",
      "sample of features: ['يصعب', 'اللي فاتت', 'الكورية الموسيقية الساعة', 'استودعك', 'اقول الله', 'الأحباب مانسا', 'تخيلي', 'تقبل انصاف الحلول', 'وأهم هدف', 'بعدم تسجيل', 'اسعد الله صباحكم', 'لعبة ما', 'جابلهم عبدالفتاح', 'وتخبز وتحضر', 'تكفى حس', 'شيء تصير', 'صندوقه السيادي وقلت', 'ما بيننا', 'وباقي الغرف للضيوف', 'الله يمحي كل', 'ملينا من', 'أغار أنت بالذات', 'يرحلون تماما', 'أحد يعرف', 'غانم', 'شفاؤك', 'ومافيه', 'حيا', 'مفيك تبطل تحس', 'تطور', 'وصباحك اسعد', 'امام النصر', 'جايز', 'يبه', 'ونرجع الساعه نتسابق', 'هذا اليوم وخير', 'السما كل ليله', 'قآلو ليش أأنت', 'المدني', 'وما لم أعلم']\n",
      "parameters\n",
      "n grams: 3\n",
      "classifier: KNeighborsClassifier\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         pos       0.86      0.46      0.60      5781\n",
      "         neg       0.64      0.93      0.76      5970\n",
      "\n",
      "    accuracy                           0.70     11751\n",
      "   macro avg       0.75      0.70      0.68     11751\n",
      "weighted avg       0.75      0.70      0.68     11751\n",
      "\n",
      "[[2664 3117]\n",
      " [ 422 5548]]\n",
      "# of features: 39232\n",
      "sample of features: ['تكمل', 'وعدد ماغفل', 'حق دون حياء', 'والله اعتقد لو', 'قبل أن نستدير', 'وقاد الحراك الثوري', 'درك يالمعيوف وحفظك', 'مرسي', 'رش يق الدايت', 'على الاهلي', 'ترافقه إلى الباب', 'محلها لابد', 'ماتحبونه بس والله', 'حب الحياة', 'الرياض', 'بالله ولا تفقد', 'عشرا رواه', 'تهب منه', 'بعد غيبته', 'والغصه والله', 'المنطقة', 'حاجه إلى رتويت', 'تصدر', 'فوق الأرض يبعث', 'لكل دعاء وشفاء', 'وإن عجز', 'شادو', 'جبان', 'جد', 'من يوم ما', 'مسبوقه', 'يادوب حيبدأ اسقاط', 'فاز افف', 'بل هي', 'تعامل', 'ليبادلنا التحية والكلمة', 'يديه أن يردهما', 'باسوا', 'غيم', 'يعني فوق']\n"
     ]
    }
   ],
   "source": [
    "ngrams = (1, 2,3)\n",
    "results = []\n",
    "pos_training = 'train_pos.tsv'\n",
    "neg_training = 'train_neg.tsv'\n",
    "\n",
    "pos_testing = 'test_pos.tsv'\n",
    "neg_testing = 'test_neg.tsv'\n",
    "\n",
    "classifiers = [LinearSVC(), SVC(), MultinomialNB(), BernoulliNB(), SGDClassifier(), \n",
    "               LogisticRegression(), MLPClassifier(), \n",
    "               DecisionTreeClassifier(max_depth=5), RandomForestClassifier(),KNeighborsClassifier(3)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for g in ngrams:\n",
    "    dataset = load(pos_training, neg_training, pos_testing, neg_testing)\n",
    "    for alg in classifiers:\n",
    "        alg_name = alg.__class__.__name__\n",
    "        r = do_sa(g, alg, alg_name, dataset)\n",
    "        results.append(r)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;\n",
    "            background-color:#3f4d6f;font-size:150%;\n",
    "            font-family:Nexa;letter-spacing:0.5px\">\n",
    "    <p style=\"padding: 8px;color:white;\"><b> | Results Summary</b></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "algorithm                |ngram     accuracy  precision recall    \n",
      "---------------------------------------------------------------------\n",
      "LinearSVC                |         1     0.770     0.770     0.770\n",
      "SVC                      |         1     0.800     0.803     0.800\n",
      "MultinomialNB            |         1     0.761     0.762     0.761\n",
      "BernoulliNB              |         1     0.758     0.763     0.758\n",
      "SGDClassifier            |         1     0.764     0.768     0.764\n",
      "LogisticRegression       |         1     0.766     0.767     0.766\n",
      "MLPClassifier            |         1     0.772     0.773     0.772\n",
      "DecisionTreeClassifier   |         1     0.572     0.694     0.572\n",
      "RandomForestClassifier   |         1     0.798     0.801     0.798\n",
      "KNeighborsClassifier     |         1     0.698     0.748     0.698\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "LinearSVC                |         2     0.774     0.774     0.774\n",
      "SVC                      |         2     0.800     0.802     0.800\n",
      "MultinomialNB            |         2     0.769     0.770     0.769\n",
      "BernoulliNB              |         2     0.762     0.772     0.762\n",
      "SGDClassifier            |         2     0.773     0.777     0.773\n",
      "LogisticRegression       |         2     0.775     0.776     0.775\n",
      "MLPClassifier            |         2     0.773     0.773     0.773\n",
      "DecisionTreeClassifier   |         2     0.572     0.693     0.572\n",
      "RandomForestClassifier   |         2     0.795     0.798     0.795\n",
      "KNeighborsClassifier     |         2     0.698     0.750     0.698\n",
      "---------------------------------------------------------------------\n",
      "---------------------------------------------------------------------\n",
      "LinearSVC                |         3     0.772     0.772     0.772\n",
      "SVC                      |         3     0.799     0.802     0.799\n",
      "MultinomialNB            |         3     0.771     0.772     0.771\n",
      "BernoulliNB              |         3     0.761     0.775     0.761\n",
      "SGDClassifier            |         3     0.774     0.777     0.774\n",
      "LogisticRegression       |         3     0.776     0.777     0.776\n",
      "MLPClassifier            |         3     0.773     0.773     0.773\n",
      "DecisionTreeClassifier   |         3     0.572     0.694     0.572\n",
      "RandomForestClassifier   |         3     0.798     0.802     0.798\n",
      "KNeighborsClassifier     |         3     0.699     0.750     0.699\n"
     ]
    }
   ],
   "source": [
    "print('{0:25}|{1:10}{2:10}{3:10}{4:10}'.format('algorithm', 'ngram', 'accuracy', 'precision', 'recall'))\n",
    "print('---------------------------------------------------------------------')\n",
    "\n",
    "# قيمة ngram السابقة\n",
    "prev_ngram = None\n",
    "\n",
    "for r in results:\n",
    "    if prev_ngram is None:\n",
    "        prev_ngram = r[1]\n",
    "    elif prev_ngram != r[1]:\n",
    "        print(\"---------------------------------------------------------------------\") \n",
    "        print(\"---------------------------------------------------------------------\") \n",
    "    prev_ngram = r[1]\n",
    "    \n",
    "    print('{0:25}|{1:10}{2:10.3f}{3:10.3f}{4:10.3f}'.format(r[0], r[1], r[2], r[3], r[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
